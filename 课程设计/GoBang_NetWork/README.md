## 这里是对最近学的内容的总结

### 蒙特卡洛树搜索：
感觉是带点赌的估值AB剪枝，模糊性的找到最好的方向，在Simulate里加入了model的计算，使得理论上是model的反复训练。
NodeExpand配上Simulate实现该算法

### 卷积的尝试：
看了好多人的写法，自己总结一下：
- 数据集的收集往往是训练结果是否成功的关键：我这里使用dataCreator随机生成数据集，可能在刚开始的训练中会不够只能，而且速度上也有欠缺
- 根据数据集进行反向传播：这一步很死板的样子，当然首先对于一个目标需要很好的建模，从15*15的棋盘最终要得到15*15的落子概率图
- 存贮神经网络：如其名，其实还有很重要的一点就是对于大图要分块再训练，不然显存会爆，这里图小，一般不用分块。
  
杀死了我好多脑细胞啊

#### 参考文献(你对比一下就知道我几乎是在重写qwq)：

- [某不知名大佬的博客](https://www.cnblogs.com/zhiyiYo/p/14683450.html)
- [UESTC PANNET](https://github.com/liangjiandeng/FusionNet)(因为最近在试着跟学校里的AI社学，这也是我改这一篇的动力)